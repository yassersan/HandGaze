#HandGaze
Real-Time Hand Gesture Recognition using C++ Â· OpenCV Â· TensorFlow Â· ONNX

ğŸš€ Overview

GestureVision is a real-time computer-vision system that detects and classifies hand gestures using a custom convolutional neural network (CNN).
The model is trained in TensorFlow, exported to ONNX, and deployed in native C++ using OpenCVâ€™s DNN module for fast inference. No Python runtime required.

ğŸ§  Features

Real-time inference (~30 FPS) with OpenCV DNN
Custom CNN trained on palm, fist, and peace gestures
Dynamic ROI detection via skin segmentation & contour tracking
ONNX model integration (TensorFlow â†’ ONNX â†’ OpenCV DNN)
Confidence thresholds and temporal smoothing for stability
Extensible: retrainable with new gestures or datasets

ğŸ§° Tech Stack

Languages: C++, Python
Libraries: OpenCV (4.x), TensorFlow (2.x), tf2onnx, ONNX
Concepts: Computer Vision, CNNs, Model Deployment, Image Processing

âš™ï¸ Setup & Installation

1ï¸âƒ£ Clone and Build (C++)
git clone https://github.com/yourusername/GestureVision.git
cd GestureVision
mkdir build && cd build
cmake ..
make -j

2ï¸âƒ£ Train a New Model (Optional)
Activate your Python virtual environment:
python3.11 -m venv tf
source tf/bin/activate
pip install -U pip tensorflow tf2onnx
python train_better.py --epochs 20 --batch 32 --class-weights

This will output:
gestures.onnx
labels.txt

3ï¸âƒ£ Run the App
./ml_gestures

ğŸ“ Learning Outcomes

Implemented end-to-end ML deployment: Python model â†’ C++ inference
Applied real-time computer vision techniques (masking, contour tracking)
Practiced cross-framework integration and ONNX optimization
Tuned data pipelines and CNN architectures for practical performance

